{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/here0009/An-Introduction-To-Applied-Bioinformatics/blob/master/hertie_transformers_gpt3_perplexity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Measuring change in perplexity with GPT-3"
      ],
      "metadata": {
        "id": "3jHnxbNdnIH4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mtr8igwZ_y5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rE6iz8gQ_zOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "## Import (and install) necessary libraries"
      ],
      "metadata": {
        "id": "vpTwzuXJmKgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndY4UnwLmB9L",
        "outputId": "1d05f002-3697-4b5a-f20a-08231ced6795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.5.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcmwWuibsPjZ",
        "outputId": "b34b6065-6f03-4d28-f918-1980994f3ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.5.1 in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1) (1.21.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AcuO6fyly-a"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "import gdown\n",
        "import gzip\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "K7ixLxkBseKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import TextDataset, LineByLineTextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments, AutoModelWithLMHead\n",
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, AutoTokenizer"
      ],
      "metadata": {
        "id": "IWxRmx9emD1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "## Function to get perplexity of a sequence\n",
        "\n",
        "This is from https://huggingface.co/docs/transformers/perplexity\n",
        "\n",
        "This is a bit complicated because we need to account for the fixed length of GPT-2. To measure the perplexity of the full test sequence (which might be longer than 512 tokens), we need to use a sliding window."
      ],
      "metadata": {
        "id": "PFtoxS3imU2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_perplexity(model, device, encodings):\n",
        "  \n",
        "  max_length = model.config.n_positions\n",
        "  stride = 512\n",
        "\n",
        "  nlls = []\n",
        "  for i in tqdm(range(0, encodings.input_ids.size(1), stride)):\n",
        "      begin_loc = max(i + stride - max_length, 0)\n",
        "      end_loc = min(i + stride, encodings.input_ids.size(1))\n",
        "      trg_len = end_loc - i  # may be different from stride on last loop\n",
        "      input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
        "      target_ids = input_ids.clone()\n",
        "      target_ids[:, :-trg_len] = -100\n",
        "\n",
        "      with torch.no_grad():\n",
        "          outputs = model(input_ids, labels=target_ids)\n",
        "          neg_log_likelihood = outputs[0] * trg_len\n",
        "\n",
        "      nlls.append(neg_log_likelihood)\n",
        "\n",
        "  ppl = torch.exp(torch.stack(nlls).sum() / end_loc)\n",
        "\n",
        "  return ppl"
      ],
      "metadata": {
        "id": "BGPsBiTSmXQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "## Function to fine-tune a model\n",
        "\n",
        "This function loads a pretrained GPT-2 model, loads a dataset, and fine-tunes the model on the dataset. Finally, we save the model for later use.\n",
        "\n",
        "The parameters are left at their default values, but you should experiment with changing them."
      ],
      "metadata": {
        "id": "M1ilchxemhGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune(target_tag, model_id, device):\n",
        "\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "    test_dataset = TextDataset(tokenizer=tokenizer,\n",
        "                                file_path=target_tag + '.txt',\n",
        "                                block_size=128)\n",
        "\n",
        "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "    training_args = TrainingArguments(output_dir=\"/sample_data\", #The output directory\n",
        "                                        overwrite_output_dir=True, #overwrite the content of the output directory\n",
        "                                        num_train_epochs=3, # number of training epochs\n",
        "                                        per_device_train_batch_size=16, # batch size for training\n",
        "                                        per_device_eval_batch_size=32,  # batch size for evaluation\n",
        "                                        eval_steps=400, # Number of update steps between two evaluations.\n",
        "                                        save_steps=800, # after # steps model is saved\n",
        "                                        warmup_steps=10 # number of warmup steps for learning rate scheduler\n",
        "                                    )\n",
        "\n",
        "    trainer = Trainer(model=model,\n",
        "                        args=training_args,\n",
        "                        data_collator=data_collator,\n",
        "                        train_dataset=test_dataset,\n",
        "                        eval_dataset=test_dataset)\n",
        "\n",
        "    trainer.train()\n",
        "    trainer.save_model('gpt2-' + '-'.join(target_tag.split()))\n",
        "\n",
        "    del model"
      ],
      "metadata": {
        "id": "QyHaFsXmmXu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "## Function to get fine-tuned perplexities\n",
        "\n",
        "Here we extract the perplexity score for each review from the fine-tuned model. We save these scores in an ordered list."
      ],
      "metadata": {
        "id": "rG4oR8MZmoJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_finetuned_perplexities(target_tag, device, model_id, sentences):\n",
        "\n",
        "    finetuned_perplexities = []\n",
        "\n",
        "    finetuned_model = GPT2LMHeadModel.from_pretrained('gpt2-' + '-'.join(target_tag.split())).to(device)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "    for _sentence in sentences:\n",
        "        _encoding = tokenizer(_sentence, return_tensors='pt', return_length=True, truncation=True)\n",
        "        _finetuned_perplexity = get_perplexity(finetuned_model, device, _encoding).item()\n",
        "        finetuned_perplexities.append(_finetuned_perplexity)\n",
        "\n",
        "    return finetuned_perplexities"
      ],
      "metadata": {
        "id": "Kx07fAsNmlou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "## Load a test dataset\n",
        "\n",
        "We load the same UCSD book review dataset that we used in our classification example. This data includes Goodreads book reviews across different genres. Using the full dataset, we can get many more genres than these."
      ],
      "metadata": {
        "id": "4v5RE-JNo09f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is where our target data is hosted on the web. You only need these paths for the book review dataset.\n",
        "\n",
        "genre_url_dict = {'poetry':                 'https://drive.google.com/uc?id=1FVD3LxJXRc5GrKm97LehLgVGbRfF9TyO',\n",
        "                  'children':               'https://drive.google.com/uc?id=1908GDMdrhDN7sTaI_FelSHxbwcNM1EzR',\n",
        "                  'comics_graphic':         'https://drive.google.com/uc?id=1V4MLeoEiPQdocCbUHjR_7L9ZmxTufPFe',\n",
        "                  'fantasy_paranormal':     'https://drive.google.com/uc?id=1THnnmE4XSCvMkGOsqapQr2cJI5amKA6X',\n",
        "                  'history_biography':      'https://drive.google.com/uc?id=1lDkTzM6zpYU-HGkVAQgsw0dBzik-Zde9',\n",
        "                  'mystery_thriller_crime': 'https://drive.google.com/uc?id=1ONpyuv0vrtd6iUEp0-zzkKqwpm3njEqi',\n",
        "                  'romance':                'https://drive.google.com/uc?id=1NpFsDQKBj_lrTzSASfyKbmkSykzN88wE',\n",
        "                  'young_adult':            'https://drive.google.com/uc?id=1M5iqCZ8a7rZRtsmY5KQ5rYnP9S0bQJVo'}"
      ],
      "metadata": {
        "id": "-A2hwbM7mtxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we'll focus just on the poetry reviews."
      ],
      "metadata": {
        "id": "TcdkbYqe1qeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdown.download(genre_url_dict['poetry'], 'poetry.json.gz', quiet=False) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "rLhPBo5So6a3",
        "outputId": "9f491368-ae35-4ecc-f062-68bdd1cc2752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1FVD3LxJXRc5GrKm97LehLgVGbRfF9TyO\n",
            "To: /content/poetry.json.gz\n",
            "100%|██████████| 49.3M/49.3M [00:00<00:00, 302MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'poetry.json.gz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_reviews(file_name,\n",
        "                 head=None):\n",
        "\n",
        "    reviews = []\n",
        "    count = 0\n",
        "\n",
        "    with gzip.open(file_name) as file:\n",
        "        for line in file:\n",
        "\n",
        "            d = json.loads(line)\n",
        "            count += 1\n",
        "\n",
        "            _book_id = d['book_id']\n",
        "\n",
        "            reviews.append(d['review_text'])\n",
        "\n",
        "            # Break if we reach the Nth line\n",
        "            if (head is not None) and (count > head):\n",
        "                break\n",
        "\n",
        "    return reviews"
      ],
      "metadata": {
        "id": "z49vxd8QpB41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = load_reviews('poetry.json.gz')\n",
        "reviews = random.sample(reviews, 200)"
      ],
      "metadata": {
        "id": "pmdd2QmmpLUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at a random review."
      ],
      "metadata": {
        "id": "Sl6gefVG1uiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(random.sample(reviews, 1)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-qpmIlXpS3Z",
        "outputId": "d18f34f5-029b-4e34-e54e-6b5e9c88c7e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Great writing by MS Woodson. Enjoyed this book about growing up from the perspective of a young girl.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_reviews = ' '.join(reviews)"
      ],
      "metadata": {
        "id": "PsU9hbpOqu7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "## Load the gpt-2 model and get the original perplexities of the reviews"
      ],
      "metadata": {
        "id": "NC0CWwZ6pu7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'\n",
        "model_id = 'gpt2'\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "aIWlada0pcKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_perplexities = []\n",
        "for i, _review in enumerate(reviews):\n",
        "    _encoding = tokenizer(_review, return_tensors='pt', return_length=True, truncation=True)\n",
        "    original_perplexities.append(get_perplexity(model, device, _encoding).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZdbkqzXrHrS",
        "outputId": "c265bca7-e1ad-4526-e04a-40a7b70e088f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 45.92it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 35.97it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 47.37it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 23.71it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 46.45it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 52.67it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 58.86it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 31.00it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 61.08it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 87.96it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 21.56it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 84.96it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 74.47it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.60it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 71.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 69.32it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 52.76it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 71.72it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.55it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 69.52it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 56.58it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.58it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 49.47it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 74.23it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 61.26it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 34.26it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 87.61it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 66.59it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 61.65it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 75.17it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 68.50it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 63.68it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 65.07it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 70.65it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.00it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 59.76it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 54.99it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 82.59it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.69it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 47.80it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 76.75it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 67.81it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 49.38it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 77.72it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 66.90it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 15.54it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 36.28it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 62.70it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 75.67it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.59it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 73.94it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 60.12it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 52.33it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 56.45it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 61.29it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 59.56it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 66.96it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 69.15it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 54.65it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 69.78it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 41.70it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 70.34it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 56.44it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 71.69it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 73.21it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 61.30it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 68.36it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 76.49it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 71.68it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 51.77it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 55.73it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 49.86it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 30.88it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 47.98it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 81.41it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 55.83it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 74.03it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 70.11it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 74.23it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 65.72it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 66.78it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 94.86it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 65.00it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 71.12it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 76.27it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 77.46it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 62.01it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 64.48it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 70.41it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 62.59it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 75.16it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 39.45it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 61.72it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 62.80it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 67.12it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 46.49it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 71.01it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 68.50it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 62.53it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 69.55it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 64.81it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 65.93it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 69.20it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 72.13it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 80.74it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 78.80it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 73.45it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 73.11it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 48.55it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 75.91it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 84.89it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 47.72it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 70.38it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 68.39it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 72.48it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 46.79it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 70.28it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 88.20it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 60.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 66.12it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 55.00it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 32.90it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 67.05it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 61.76it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 53.76it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 73.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 43.40it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 64.07it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 64.42it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 72.78it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 73.37it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 90.59it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 69.67it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 61.47it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 46.86it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 49.58it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 34.31it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 23.58it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 16.26it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 23.40it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 46.45it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 55.26it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 18.24it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 56.72it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 54.74it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 55.06it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 41.72it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 43.58it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 61.50it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 40.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 47.57it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 39.96it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 45.06it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 56.69it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 53.60it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 53.97it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 56.93it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 52.23it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 46.15it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 49.62it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 55.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 53.16it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 52.83it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 58.15it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.78it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 59.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 44.81it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.48it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 51.62it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 27.36it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 49.99it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 51.21it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 54.50it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 52.81it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 56.02it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 58.16it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 49.01it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 52.63it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 35.06it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.51it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 58.40it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 40.66it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 47.29it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 50.54it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 46.49it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 46.36it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 40.86it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 30.33it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 48.34it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 15.71it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 19.63it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 59.67it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 63.37it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 22.35it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 27.98it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 19.37it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 77.88it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 69.57it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 68.33it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "## Fine-tune the model on the reviews"
      ],
      "metadata": {
        "id": "x0edywffqT8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We fine-tune our pretrained model on a set of poetry reviews. We can watch the fine-tuning process and the training loss in the notebook."
      ],
      "metadata": {
        "id": "lML0S0it17cz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a file containing the training data\n",
        "dataset_file = open('poetry.txt', 'w')\n",
        "dataset_file.write(flattened_reviews)\n",
        "dataset_file.close()\n",
        "\n",
        "# Fine-tune on the file created above\n",
        "fine_tune('poetry', model_id, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "A_il4UFxp-gC",
        "outputId": "5355aacf-e9ca-4917-fd22-dfbc35f156bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (22718 > 1024). Running this sequence through the model will result in indexing errors\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 177\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 36\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [36/36 00:21, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to gpt2-poetry\n",
            "Configuration saved in gpt2-poetry/config.json\n",
            "Model weights saved in gpt2-poetry/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "## Get the new perplexities of the reviews"
      ],
      "metadata": {
        "id": "ZxDBSZkNqbsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just as we did for the original perplexities, we'll measure the perplexity of each review after fine-tuning the pretrained model."
      ],
      "metadata": {
        "id": "m5pHeM3k2T47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_perplexities = get_finetuned_perplexities('poetry', device, model_id, reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Mo_35bbqXH3",
        "outputId": "75ba0061-ad32-4367-ee2a-6f6c252eed88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file gpt2-poetry/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading weights file gpt2-poetry/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2-poetry.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.21.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.21.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 48.65it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 34.96it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 54.66it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 25.67it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 34.09it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 42.00it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 51.79it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 38.28it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 59.87it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 72.42it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 21.07it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 88.85it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 93.40it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 71.38it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 65.00it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 61.37it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 73.37it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 61.02it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 73.41it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 65.60it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 69.39it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 76.27it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 64.46it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 96.98it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 60.69it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 33.07it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 73.39it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 75.16it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 59.36it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 87.30it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 74.93it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 70.98it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 52.57it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 79.12it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 73.11it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 58.64it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 55.00it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 56.35it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 62.81it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 43.14it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 69.33it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.71it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 69.26it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 89.05it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 70.04it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 15.85it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 36.94it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 49.70it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 63.97it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 61.29it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 68.92it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 67.74it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 56.84it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 59.12it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 67.62it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 71.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 66.36it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 70.41it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 63.63it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 65.88it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 39.01it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 67.01it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 61.18it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 82.91it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 63.06it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 59.96it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 90.84it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 73.46it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 92.63it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 50.07it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 65.35it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 54.14it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 33.19it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 46.70it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 75.46it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 58.26it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 74.29it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 89.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 71.13it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 58.38it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 65.34it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 72.85it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 70.93it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 78.62it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 66.30it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 58.69it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 68.50it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 66.23it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 72.67it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 73.03it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 75.12it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 36.95it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 52.86it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 60.85it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 59.98it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 47.64it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 70.93it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.96it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 65.75it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 77.60it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 63.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 68.11it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 68.74it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 68.42it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 67.30it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 65.57it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 73.08it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 73.72it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 92.43it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 71.17it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 92.80it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 43.43it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 68.32it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 88.74it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.02it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 49.11it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 67.82it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 86.99it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 53.08it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 71.28it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 60.79it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 32.30it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 62.28it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 54.66it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 69.32it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 89.33it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 59.20it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 58.57it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 50.27it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 66.29it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 54.84it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 72.15it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 72.39it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 69.00it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 63.60it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 75.77it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 73.14it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 65.62it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 74.42it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 64.78it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 72.33it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 62.92it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 22.59it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.33it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 56.94it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 56.91it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 67.71it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 77.58it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 74.19it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 89.72it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 65.13it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 73.31it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 78.96it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 89.85it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 67.51it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 73.87it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 79.51it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 54.68it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 60.59it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 57.48it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 81.44it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 60.30it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 78.23it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 69.97it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 75.51it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 71.74it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 61.68it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 65.55it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 62.11it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 32.24it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 69.14it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 67.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 69.47it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 69.31it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 65.81it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 71.10it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 87.47it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 67.32it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 37.39it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 65.81it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 53.41it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 63.00it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 70.52it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 66.23it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 62.16it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 63.45it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 64.32it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 62.86it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 60.48it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 17.13it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 19.02it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 62.34it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 62.71it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 22.14it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 27.79it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 20.65it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 72.57it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 60.48it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 74.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's re-arrange all our perplexity data into a single pandas dataframe. This will allow us to examine the data (and differences between the original and fine-tuned perplexities) more easily."
      ],
      "metadata": {
        "id": "OryjKw3r2Z8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity_output_dicts = []\n",
        "for i, p in enumerate(finetuned_perplexities):\n",
        "    perplexity_output_dicts.append({'fine_tuned_tag': 'poetry',\n",
        "                                    'review': reviews[i],\n",
        "                                    'original_ppl': original_perplexities[i],\n",
        "                                    'new_ppl': p})\n",
        "perplexity_output_df = pd.DataFrame(perplexity_output_dicts)\n",
        "perplexity_output_df.to_csv('perplexity_output.poetry.csv')"
      ],
      "metadata": {
        "id": "rSQQ2L5ouOPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity_output_df.sample(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Z48hCnq8vmwc",
        "outputId": "4a4cb157-f8be-460c-e639-6de6a369669d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    fine_tuned_tag                                             review  \\\n",
              "160         poetry                 Well, that was frickin' brilliant.   \n",
              "14          poetry  I had this title in mind for a while after rea...   \n",
              "109         poetry  So amazing! \\n This book hit me deeply on so m...   \n",
              "\n",
              "     original_ppl    new_ppl  \n",
              "160     23.303785  16.099445  \n",
              "14      29.351795  20.276806  \n",
              "109     75.824944  33.489891  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd81db5b-2bcf-4332-b01a-0c174954fe97\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fine_tuned_tag</th>\n",
              "      <th>review</th>\n",
              "      <th>original_ppl</th>\n",
              "      <th>new_ppl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>poetry</td>\n",
              "      <td>Well, that was frickin' brilliant.</td>\n",
              "      <td>23.303785</td>\n",
              "      <td>16.099445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>poetry</td>\n",
              "      <td>I had this title in mind for a while after rea...</td>\n",
              "      <td>29.351795</td>\n",
              "      <td>20.276806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>poetry</td>\n",
              "      <td>So amazing! \\n This book hit me deeply on so m...</td>\n",
              "      <td>75.824944</td>\n",
              "      <td>33.489891</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd81db5b-2bcf-4332-b01a-0c174954fe97')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd81db5b-2bcf-4332-b01a-0c174954fe97 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd81db5b-2bcf-4332-b01a-0c174954fe97');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity_output_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "B1Mx9DVovsse",
        "outputId": "0fbf5423-0aad-4e50-c777-14c4be11f44b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       original_ppl      new_ppl\n",
              "count    200.000000   200.000000\n",
              "mean     284.429726    95.723942\n",
              "std      987.660772   147.647705\n",
              "min       11.465781     9.088837\n",
              "25%       41.840387    28.522824\n",
              "50%       77.779865    50.149952\n",
              "75%      225.305412   103.709164\n",
              "max    12867.959961  1312.637573"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ad23d25-bf64-4561-bd6e-935aa9195baa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_ppl</th>\n",
              "      <th>new_ppl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>200.000000</td>\n",
              "      <td>200.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>284.429726</td>\n",
              "      <td>95.723942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>987.660772</td>\n",
              "      <td>147.647705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>11.465781</td>\n",
              "      <td>9.088837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>41.840387</td>\n",
              "      <td>28.522824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>77.779865</td>\n",
              "      <td>50.149952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>225.305412</td>\n",
              "      <td>103.709164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>12867.959961</td>\n",
              "      <td>1312.637573</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ad23d25-bf64-4561-bd6e-935aa9195baa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ad23d25-bf64-4561-bd6e-935aa9195baa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ad23d25-bf64-4561-bd6e-935aa9195baa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity_output_df['change_ppl'] = perplexity_output_df['new_ppl'] - perplexity_output_df['original_ppl']"
      ],
      "metadata": {
        "id": "A62JGOjtwEvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which reviews' perplexity scores have improved the most after fine-tuning? Remember that we fine-tuned and tested on the same set of reviews, so we expect everything to improve.\n",
        "\n",
        "Let's print the review texts and think about why these reviews improve the most."
      ],
      "metadata": {
        "id": "ZY1yyOnhxhSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity_output_df = perplexity_output_df.sort_values(by=['change_ppl'], ascending=True)\n",
        "\n",
        "for i, r in perplexity_output_df.head(10).iterrows():\n",
        "    print(round(r['change_ppl'], 2), '\\t', ' '.join(r['review'].split()))\n",
        "print('...')\n",
        "for i, r in perplexity_output_df.tail(10).iterrows():\n",
        "    print(round(r['change_ppl'], 2), '\\t', ' '.join(r['review'].split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R0VEC5Zvzwo",
        "outputId": "2cd846d0-f316-48bb-b2ee-d6f83caefb99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-12578.75 \t swnt lGyb ! !\n",
            "-2661.87 \t keingat guru Bahasa Indonesia sewaktu SMA... inget semangat ngajarnya...\n",
            "-2084.62 \t lbr@ f~ Hb llh\n",
            "-1712.72 \t m 'nt swy fs `dyh lknh l tkl bsr`@ wDrbth `nydh\n",
            "-1459.25 \t mmlun ,, wkf~ !!\n",
            "-917.39 \t fltrHm~ D`f~ ... wql@ Hylt~ hdh `tb lHb ...... ll'Hbb\n",
            "-844.77 \t w nWy 'uHbk nt bdy@ rwHy wnt lkhtm , yTyr lHmm yHT lHmm ..\n",
            "-690.49 \t my favourite poem , ever !!!\n",
            "-648.16 \t Hy'run 'n byn 'n ybd' lfrH w'laW ybd' mkhf@a ynthy .\n",
            "-598.96 \t mn 'jml m qr't =)\n",
            "...\n",
            "-5.26 \t I love the darkness of Poe's short stories. If you haven't read them, you are simply missing out.\n",
            "-4.6 \t My favorite of everything I've read of his so far. Which isn't that much, but I'm in a much better mood now.\n",
            "-4.53 \t As a complete work I would give part I and part II 3 stars. If I could rate the parts separately I would give the first part 4 stars and the second part 2 stars. I liked the first part a lot - a lot of things were happening but the story was still consistent. I did not like the second part - it got confusing and I didn't see any relation to the first part.\n",
            "-4.17 \t I read 1/3 of this book but had to return it to the library before I had finished it. My husband bought me a copy at a book sale a few months ago, and I've decided to pick it up again, starting from the beginning. I was loving the richness of language and imagery when I first picked it up, and so I'm looking forward to starting to read it again. I think Notley is creating truly original, breathtaking work.\n",
            "-2.38 \t This confuses the hell out of me, and I'm thankful for that.\n",
            "-1.04 \t Fantastic!\n",
            "3.26 \t 3.5\n",
            "6.76 \t BEAUTIFUL\n",
            "22.54 \t Screaming.\n",
            "48.39 \t This. Book.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "## Examine perplexities when fine-tuning on different genres\n",
        "\n",
        "If we re-ran the above code with many different genres, where we fine-tuned and tested the perplexity on each pair of genres, we might get output like the following.\n",
        "\n",
        "Each cell entry in this heatmap represents a change in perplexity. The genres on the y-axis represent the genre used for fine-tuning, while the genres on the x-axis represent the genre's whose perlexity values were tested."
      ],
      "metadata": {
        "id": "0HSgNeSqtd5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('heatmap.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 41
        },
        "id": "NC9Aod1KthYi",
        "outputId": "b87146c8-39fd-40a2-94e9-3a093005483f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "heatmap.jpg"
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lwuPPh2O25bA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}